# -*- coding: utf-8 -*-
"""voice to image .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w62xPI5LG5kyl2mpzWxz9iM90kvz2CzP

**Install Required Libraries**
"""

!nvidia-smi

!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
!pip install diffusers transformers accelerate

from diffusers import StableDiffusionPipeline
import torch

# Load the Stable Diffusion model
pipe = StableDiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16)

# Move the model to GPU
pipe = pipe.to("cuda")

# Generate an image
prompt = "A futuristic cityscape at sunset"
image = pipe(prompt).images[0]

# Display the image
image.show()

"""**Upload Audio File**"""

from google.colab import files

uploaded = files.upload()
audio_file = list(uploaded.keys())[0]

"""**Convert Voice to Text Using Whisper**"""

import whisper

# Load the Whisper model
model = whisper.load_model("base")

# Transcribe the audio file
result = model.transcribe(audio_file)
text = result["text"]

print("Transcribed Text:", text)

"""**Generate Image from Text Using Stable Diffusion**"""

import torch
from diffusers import StableDiffusionPipeline

# Load the Stable Diffusion model
pipe = StableDiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16)
pipe = pipe.to("cuda")

# Generate the image
prompt = "Imagine a vast desert with a lone traveler riding a camel under a setting sun, casting long shadows on the dunes."  # Use the transcribed text as the prompt
image = pipe(prompt).images[0]

# Display the image
image.show()

print("Loading model...")
pipe = StableDiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16)
print("Model loaded. Moving to GPU...")
pipe = pipe.to("cuda")
print("Generating image...")
image = pipe(prompt).images[0]
print("Image generated.")

display(image)

